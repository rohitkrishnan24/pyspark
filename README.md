
# IPL Data Analysis with PySpark ETL on Databricks and S3

Data Extraction:

Loaded the IPL dataset into an Amazon S3 bucket for secure and scalable storage.

Data Transformation:

Used PySpark within the Databricks platform to process and transform the data.
Performed data cleaning, filtering, and aggregation.
Derived meaningful insights through PySpark and SQL operations.

Data Loading:

Stored the transformed data back in S3 or made it available within Databricks for further analysis.
This ETL process facilitated efficient handling of large datasets, enabling the extraction of valuable insights into IPL performance metrics.

## Screenshots

![App Screenshot](https://drive.google.com/file/d/1TKVsFx34Sp3VNTxQEpP8nLJuS91FxZpU/view?usp=drive_link)




## Tech Stack

**Client:** React, Redux, TailwindCSS

**Server:** Node, Express

